<!DOCTYPE HTML>
<html>
	<head>
		<title>Jianfeng Dong | Homepage </title>
		<meta name="viewport" content="width=device-width, initial-scale=1">
		<link href="./css/style.css" rel="stylesheet" type="text/css"  media="all" />
		<link rel="stylesheet" href="./css/main.min.css">
		<!-- <link href='http://fonts.googleapis.com/css?family=Karla' rel='stylesheet' type='text/css'> -->
		<script type="text/javascript" src="js/jquery-1.11.0.min.js"></script>
		<script type="text/javascript">
		jQuery(document).ready(function($) {
			$(".scroll").click(function(event){		
				event.preventDefault();
				$('html,body').animate({scrollTop:$(this.hash).offset().top},1200);
			});
		});
		</script>
	</head>
	<body>
		
	<div class="header">
		<div class="wrap">

			<div class="logo">
				<a href="index.html">Jianfeng</a>
			</div>
			
			<div class="top-nav" >
				<ul>
					<li class="active"><a href="#me" class="scroll">Me</a></li>
					<!-- <li><a href="#biography" class="scroll">Biography</a></li> -->
					<li><a href="./publications.html">Publications</a></li>
					<li><a href="./misc.html">Misc</a></li>
					<!-- <li><a href="http://blog.csdn.net/danieljianfeng">Blog</a></li> -->
				</ul>
			</div>
			<div class="clear"> </div>
			
	     </div>
	</div>


	<div class="content">
		<div class="grid1" id="me" style="background:url(images/banner.jpg) no-repeat 0 0; background-position: center;">
			<a href="#"><img src="./images/daniel3.jpg" title="jianfeng dong" /></a>
			<h3>Jianfeng Dong</h3>
			<h4>Zhejiang GongShang University<h4>
            <h4>dongjf24@gmail.com </h4>

            <a href="https://scholar.google.com/citations?user=8-zdk9wAAAAJ">
            <img src="./images/google-scholar-logo.png" width="40"/></i>
            </a>
            <a href="https://github.com/danieljf24">
            <img src="./images/GitHub.png" width="40"/></i>
            </a>
			
		</div>
		<div class="grid2" id="biography">
			<h3>Biography</h3>
			<p>
				Jianfeng Dong is currently a Research Professor at the College of Computer and Information Engineering, Zhejiang GongShang University, and also a Visiting Scholar at Alibaba-Zhejiang University Joint Research Institute of Frontier Technologies (<a href="https://azft.alibaba.com/">AZFT</a>).
				He received his Doctor degree from Zhejiang University in 2018, under the supervision of Prof. Duanqing Xu.  
                He was also a visiting Ph.D. student in Multimedia Computing Lab at Renmin University of China, working with Prof. <a href="http://lixirong.net/">Xirong Li</a> in 2015-2016, and in UBTECH Sydney Artificial Intelligence Centre at The University of Sydney, working with Prof. <a href="https://www.sydney.edu.au/engineering/about/our-people/academic-staff/dacheng-tao.html">Dacheng Tao</a> in 2017.             
                His research direction is Multimieda Understanding, Computer Vision and Deep Learning.
			</p>
		</div>

		
	        <div class="grid2" id="biography">
				<h3>Recent News</h3>
				<!-- <ul style="list-style-type:square;"> -->
				<!-- <ul>
					<li>
						* 26-30 October, 2015: One paper accepted by <a href="http://www.acmmm.org/2015/">ACM MM 2015</a>. 
					</li>
					<li>
						* 21-26 June, 2014: Student Volunteer in <a href="http://www.icml.cc/2014/">ICML 2014</a>.
					</li>
				</ul> -->
                <ul>
                <li> Feb, 2021: One papers accepted by TPAMI (CCF A, IF:17.861). Congrats to Chaoxi.
                <li> Jan, 2021: One papers accepted by Neurocomputing (IF:4.438). Congrats to Zhongzi.
				<li> Jan, 2021: Two papers accepted by ICASSP 2021 (CCF B). Congrats to Zhe, Fenghao, and Zhixiao. 
				<li> Oct, 2020: One papers accepted by COLING 2020 (CCF B).
				<li> Aug, 2020: Two papers accepted by ACM MM 2020 (CCF A). 
				<li> Apr, 2020: One paper accepted by SIGIR 2020 (CCF A). 
				<li> Feb, 2020: One paper accepted by CVPR 2020 (CCF A) as oral paper. 
				<li> Nov, 2019: One paper accepted by AAAI 2020 (CCF A). 
				</ul> 
			</div>
	




		<div class="grid3" id="publication">

			<div class="grid3-year"> <h3> Selected Publications <h3> </div>


            <div class="row">
		    <div class="grid3-content">
			    <div class="col-md-4">
			         <center><a href="./pubs/imgs/aaai2020_fine_grained.jpg"><img class="enlarge" src="./pubs/imgs/aaai2020_fine_grained.jpg" width="300" style="border:1px solid black"></a></center>        
			    </div>

		        <div class="col-md-8">
		            <h4><b>Fine-Grained Fashion Similarity Learning by Attribute-Specific Embedding Network</b></h4>
		            <h5> Zhe Ma, <b>Jianfeng Dong#</b>, Yao Zhang, Zhongzi Long, Yuan He, Hui Xue, Shouling Ji. <b>AAAI</b> 2020.</h5>
		            <h6>   
		            	[<a href="pubs/papers/aaai2020_fine_grained.pdf">paper</a>] 
		            	[<a href="pubs/poster/poster_aaai2020_fine_grained.pdf">poster</a> ] 
		            	[<a href="https://github.com/Maryeon/asen">code</a>]
		            	[<a href="https://www.jiqizhixin.com/articles/2020-02-13-12?from=timeline&isappinstalled=0">news</a>]
		            </h6>
		        </div>
		    </div>
		    </div>
		    <br>



            <div class="row">
		    <div class="grid3-content">
			    <div class="col-md-4">
			         <center><a href="./pubs/imgs/sigir2020_video_text.jpg"><img class="enlarge" src="./pubs/imgs/sigir2020_video_text.jpg" width="300" style="border:1px solid black"></a></center>        
			    </div>

		        <div class="col-md-8">
		            <h4><b> Tree-Augmented Cross-Modal Encoding for Complex-Query
                            Video Retrieval</b></h4>
		            <h5> Xun Yang, <b>Jianfeng Dong#</b>, Yixin Cao, Xun Wang, Meng Wang, Tat-Seng Chua. <b>SIGIR</b> 2020.</h5>
		            <h6>   
		            	[<a href="pubs/papers/sigir2020_video_text.pdf">paper</a>] 
		            	[<a href="pubs/slides/slides_sigir2020_video_text.pdf">slides</a>] 
		            </h6>
		        </div>
		    </div>
		    </div>
		    <br>



            <div class="row">
		    <div class="grid3-content">
			    <div class="col-md-4">
			         <center><a href="./pubs/imgs/cvpr2019_dual_encoding.jpg"><img class="enlarge" src="./pubs/imgs/cvpr2019_dual_encoding.jpg" width="300" style="border:1px solid black"></a></center>        
			    </div>

		        <div class="col-md-8">
		            <h4><b> Dual Encoding for Zero-Example Video Retrieval</b></h4>
		            <h5> <b>Jianfeng Dong#</b>, Xirong Li, Chaoxi Xu, Shouling Ji, Yuan He, Gang Yang, Xun Wang. <b>CVPR</b> 2019.</h5>
		            <h6>   
		            	[<a href="pubs/papers/cvpr2019_dual_encoding.pdf">paper</a>] 
		            	[<a href="pubs/slides/slides_cvpr2019_dual_encoding.pdf">slides</a>]
		                [<a href="pubs/poster/poster_cvpr2019_dual_encoding.pdf">poster</a>]
		            	[<a href="https://github.com/danieljf24/dual_encoding">code</a>]
		            </h6>
		        </div>
		    </div>
		    </div>
		    <br>



		    <div class="row">
		    <div class="grid3-content">
			    <div class="col-md-4">
			         <center><a href="./pubs/imgs/mm2019-w2vvpp.jpg"><img class="enlarge" src="./pubs/imgs/mm2019-w2vvpp.jpg" width="300" style="border:1px solid black"></a></center>        
			    </div>

		        <div class="col-md-8">
		            <h4><b> W2VV++: Fully Deep Learning for Ad-hoc Video Search </b></h4>
		            <h5> Xirong Li, Chaoxi Xu, Gang Yang, Zhineng Chen, <b>Jianfeng Dong#</b>. <b>ACM MM</b> 2019. (<b>Winner of NIST TRECVID 2018 Ad-hoc Video Search task</b>)</h5>
		            <h6>   
		            	[<a href="pubs/papers/mm2019-w2vvpp.pdf">paper</a>] 
		            	[<a href="https://github.com/li-xirong/w2vvpp">code</a>]
		            </h6>
		        </div>
		    </div>
		    </div>
		    <br>


            <div class="row">
		    <div class="grid3-content">
			    <div class="col-md-4">
			         <center><a href="./pubs/imgs/tkde2019_hulu.jpg"><img class="enlarge" src="./pubs/imgs/tkde2019_hulu.jpg" width="300" style="border:1px solid black"></a></center>        
			    </div>

		        <div class="col-md-8">
		            <h4><b> Feature Re-Learning with Data Augmentation for Video Relevance Prediction</b></h4>
		            <h5> <b>Jianfeng Dong</b>, Xun Wang, Leimin Zhang, Chaoxi Xu, Gang Yang, Xirong Li. <b>TKDE</b> 2019.</h5>
		            <h6>   
		            	[<a href="pubs/papers/tkde2019_hulu.pdf">paper</a>] 
		            	[<a href="https://github.com/danieljf24/cbvr">code</a>]
		            </h6>
		        </div>
		    </div>
		    </div>
		    <br>


            <div class="row">
		    <div class="grid3-content">
			    <div class="col-md-4">
			         <center><a href="./pubs/imgs/mm2018_hulu.jpg"><img class="enlarge" src="./pubs/imgs/mm2018_hulu.jpg" width="300" style="border:1px solid black"></a></center>        
			    </div>

                <div class="col-md-8">
		            <h4><b> Feature Re-Learning with Data Augmentation for Content-based Video Recommendation</b></h4>
		            <h5> <b>Jianfeng Dong</b>, Xirong Li, Chaoxi Xu, Gang Yang, Xun Wang. <b>ACM MM</b> 2018. (<b>Winner of Hulu Content-based Video Relevance Prediction Challenge 2018</b>) </h5>
		            <h6>   
		            	[<a href="pubs/papers/mm2018-hulu.pdf">paper</a>] 
		            	[<a href="pubs/slides/slides-mm2018-hulu.pdf">slides</a>]
		            	[<a href="https://github.com/danieljf24/cbvr">code</a>]
		            </h6>
		        </div>
		    </div>
		    </div>
		    <br>


            <div class="row">
		    <div class="grid3-content">
			    <div class="col-md-4">
			         <center><a href="./pubs/imgs/tmm2018_w2vv.jpg"><img class="enlarge" src="./pubs/imgs/tmm2018_w2vv.jpg" width="300" style="border:1px solid black"></a></center>        
			    </div>

                <div class="col-md-8">
		            <h4><b> Predicting Visual Features from Text for Image and Video Caption Retrieval</b></h4>
		            <h5> <b>Jianfeng Dong</b>, Xirong Li, and Cees G. M. Snoek. <b>TMM</b> 2018. (<b>Winner of NIST TRECVID 2016 Video-to-Text task</b>)  </h5>
		            <h6>   
		            	[<a href="pubs/papers/tmm2018_w2vv.pdf">paper</a>] 
		            	[<a href="https://github.com/danieljf24/w2vv">code</a>]
		            </h6>
		        </div>
		    </div>
		    </div>
		    <br>



            <div class="row">
		    <div class="grid3-content">
			    <div class="col-md-4">
			         <center><a href="./pubs/imgs/tmm2018-web-image-retrieval.jpg"><img class="enlarge" src="./pubs/imgs/tmm2018-web-image-retrieval.jpg" width="300" style="border:1px solid black"></a></center>        
			    </div>

                <div class="col-md-8">
		            <h4><b> Cross-Media Similarity Evaluation for Web Image Retrieval in the Wild </b></h4>
		            <h5> <b>Jianfeng Dong</b>, Xirong Li, Duanqing Xu. <b>TMM</b> 2018.</h5>
		            <h6>   
		            	[<a href="pubs/papers/tmm2018-web-image-retrieval.pdf">paper</a>]
		            	[<a href="https://github.com/danieljf24/text2image">code</a>]
		            </h6>
		        </div>
		    </div>
		    </div>
		    <br>


            <div class="row">
		    <div class="grid3-content">
			    <div class="col-md-4">
			         <center><a href="./pubs/imgs/mm2017-im2sent.jpg"><img class="enlarge" src="./pubs/imgs/mm2017-im2sent.jpg" width="300" style="border:1px solid black"></a></center>        
			    </div>

                <div class="col-md-8">
		            <h4><b> Fluency-Guided Cross-Lingual Image Captioning </b></h4>
		            <h5> Weiyu Lan, Xirong Li, <b>Jianfeng Dong</b>. <b>ACM MM</b> 2017.</h5>
		            <h6>   
		            	[<a href="pubs/papers/mm2017-im2sent.pdf">paper</a>]
		            	[<a href="pubs/slides/slides-mm2017-im2sent.pdf">slides</a>]
		            	[<a href="https://github.com/weiyuk/fluent-cap">code</a>]
		            </h6>
		        </div>
		    </div>
		    </div>
		    <br>



            <div class="row">
		    <div class="grid3-content">
			    <div class="col-md-4">
			         <center><a href="./pubs/imgs/mm2016-video2text.jpg"><img class="enlarge" src="./pubs/imgs/mm2016-video2text.jpg" width="300" style="border:1px solid black"></a></center>        
			    </div>

                <div class="col-md-8">
		            <h4><b> Early Embedding and Late Reranking for Video Captioning </b></h4>
		            <h5> <b>Jianfeng Dong</b>, Xirong Li, Weiyu Lan, Yujia Huo, and Cees G. M. Snoek. <b>ACM MM</b> 2016. (<b>Grand Challenge Award</b>)</h5>
		            <h6>   
		            	[<a href="pubs/papers/mm2016-video2text.pdf">paper</a>]
		            	[<a href="pubs/slides/slides-mm2016-video2text.pdf">slides</a>]
		            </h6>
		        </div>
		    </div>
		    </div>
		    <br>


            <div class="row">
		    <div class="grid3-content">
			    <div class="col-md-4">
			         <center><a href="./pubs/imgs/icmr2016_chisent.jpg"><img class="enlarge" src="./pubs/imgs/icmr2016_chisent.jpg" width="300" style="border:1px solid black"></a></center>        
			    </div>

                <div class="col-md-8">
		            <h4><b> Adding Chinese Captions to Images </b></h4>
		            <h5> Xirong Li, Weiyu Lan, <b>Jianfeng Dong</b>, Hailong Liu. <b>ICMR</b> 2016.</h5>
		            <h6>   
		            	[<a href="pubs/papers/icmr2016_chisent.pdf">paper</a>]
		            	[<a href="http://lixirong.net/datasets/flickr8kcn">data</a>]
		            </h6>
		        </div>
		    </div>
		    </div>
		    <br>



            <div class="row">
		    <div class="grid3-content">
			    <div class="col-md-4">
			         <center><a href="./pubs/imgs/mm2015-cmrf.jpg"><img class="enlarge" src="./pubs/imgs/mm2015-cmrf.jpg" width="300" style="border:1px solid black"></a></center>        
			    </div>

                <div class="col-md-8">
		            <h4><b> Early Embedding and Late Reranking for Video Captioning </b></h4>
		            <h5> <b>Jianfeng Dong</b>, Xirong Li, Shuai Liao, Jieping Xu, Duanqing Xu, Xiaoyong Du. <b>ACM MM</b> 2015. (<b>Winner of MSR-Bing Image Retrieval Challenge</b>)</h5>
		            <h6>   
		            	[<a href="pubs/papers/mm2015-cmrf.pdf">paper</a>]
		            	[<a href="pubs/slides/sides-mm2015-cmrf.pdf">slides</a>]
		            	[<a href="https://github.com/danieljf24/cmrf">code</a>]
		            	[<a href="http://lixirong.net/datasets/mm2015cmrf">data</a>]
		            </h6>
		        </div>
		    </div>
		    </div>
		    <br>


		</div>	



		<!-- <div class="twiiter-box">
			<a href="#"><img src="./images/twitt.png" title="twitter-count" /></a>
			<p>be distracted by the readable content of a page when <a href="#">#looking at its layout.</a> Via <a href="#">@readabled</a></p>
		</div>

		<div class="contact" id="contact">
			<h3>Feed Back</h3>
			<p>Reader will be distracted by the readable content of a page when looking at its layout.</p>
			<form>
			<input type="text" class="textbox" value="Name:" onfocus="this.value = '';" onblur="if (this.value == '') {this.value = 'Name';}">
			<input type="text" class="textbox" value="Email:" onfocus="this.value = '';" onblur="if (this.value == '') {this.value = 'Email';}">
			<textarea value="Message:" onfocus="this.value = '';" onblur="if (this.value == '') {this.value = 'Message';}">Message</textarea>
			<input type="submit" value="Send">
			</form>
		</div>


		<div class="catch-me">
			<h3>SAY HELLO</h3>
			<p>Reader will be distracted by the readable content of a page when looking at its layout.Ipsum is simply dummy text of the printing and typesetting industry.when an unknown printer took a galley of type and scrambled it to make a type specimen book.</p>
			<ul>
				<li><a href="#"><img src="./images/facebook.png" title="facebook" /></a></li>
				<li><a href="#"><img src="./images/rss.png" title="Rss" /></a></li>
				<li><a href="#"><img src="./images/googlepluse.png" title="Googlepluse" /></a></li>
			</ul>
		</div> -->
	</div>

	<!-- <script type="text/javascript" id="clustrmaps" src="//clustrmaps.com/map_v2.js?d=vBZrWCAzr4X0lfuKXstITg4d7FnXAHwucAhzs3T5S9Y&cl=ffffff&w=a"></script> -->


	<div class="footer">
		<p>Homepage of Jianfeng Dong</p>
	</div>

	</body>
</html>

